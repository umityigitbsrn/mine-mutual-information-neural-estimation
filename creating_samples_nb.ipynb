{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T01:48:46.691334674Z",
     "start_time": "2023-09-29T01:48:46.075699614Z"
    }
   },
   "id": "13468cb86b4d45ff"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# constants\n",
    "degree_of_poly_T = 5\n",
    "num_of_poly_N = 100\n",
    "prime_p = 2**26 - 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T01:48:47.910146329Z",
     "start_time": "2023-09-29T01:48:47.852160095Z"
    }
   },
   "id": "341f8e22017b510b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# creating the dataset\n",
    "## starting from basic shamir secret sharing with real numbers\n",
    "## creating the polynomials first (reverse order - higher degree in the beginning)\n",
    "first_poly_dataset = np.random.randint(1, prime_p, size=(num_of_poly_N, degree_of_poly_T), dtype=np.int64) # to create a resulting polynomial without any zero in the largest degree\n",
    "second_poly_dataset = np.random.randint(1, prime_p, size=(num_of_poly_N, degree_of_poly_T), dtype=np.int64)\n",
    "multiplied_poly_dataset = np.empty((num_of_poly_N, 2 * (degree_of_poly_T - 1) + 1), dtype='object')\n",
    "for idx in range(num_of_poly_N):\n",
    "    multiplied_poly_dataset[idx] = np.polymul(first_poly_dataset[idx], second_poly_dataset[idx])\n",
    "\n",
    "multiplied_poly_dataset = multiplied_poly_dataset % prime_p\n",
    "mutual_information_dataset = np.empty((num_of_poly_N, 2 * (degree_of_poly_T - 1) + 3), dtype='object')\n",
    "mutual_information_dataset[:, :(2 * (degree_of_poly_T - 1) + 1)] = multiplied_poly_dataset\n",
    "mutual_information_dataset[:, -2] = second_poly_dataset[:, -1]\n",
    "mutual_information_dataset[:, -1] = first_poly_dataset[:, -1]\n",
    "mutual_information_dataset = np.fliplr(mutual_information_dataset)\n",
    "mutual_information_dataset = mutual_information_dataset.astype(np.float64)\n",
    "mutual_information_dataset = torch.from_numpy(mutual_information_dataset.copy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T01:48:49.228055647Z",
     "start_time": "2023-09-29T01:48:49.224312289Z"
    }
   },
   "id": "e46bc8c925e5e02d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-29T01:48:51.223750654Z",
     "start_time": "2023-09-29T01:48:51.222021048Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample from distributions for one dataset\n",
    "def sample_for_iteration(batch_size, dataset):\n",
    "    # sampling from joint distribution\n",
    "    joint_idx = np.random.choice(dataset.shape[0], size=batch_size, replace=False)\n",
    "    joint_batch = torch.empty((batch_size, dataset.shape[-1]), dtype=dataset.dtype)\n",
    "    joint_batch = dataset[joint_idx]\n",
    "    \n",
    "    # sampling from marginal distributions\n",
    "    ## first sample only for the secrets\n",
    "    secret_marginal_idx = np.random.choice(dataset.shape[0], size=batch_size, replace=False)\n",
    "    coeff_marginal_idx = np.random.choice(dataset.shape[0], size=batch_size, replace=False)\n",
    "    marginal_batch = torch.empty((batch_size, dataset.shape[-1]), dtype=dataset.dtype)\n",
    "    marginal_batch[:, :2] = dataset[secret_marginal_idx, :2]\n",
    "    marginal_batch[:, 2:] = dataset[coeff_marginal_idx, 2:]\n",
    "    \n",
    "    return joint_batch, marginal_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Mine(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=100):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        nn.init.normal_(self.fc1.weight,std=0.02)\n",
    "        nn.init.constant_(self.fc1.bias, 0)\n",
    "        nn.init.normal_(self.fc2.weight,std=0.02)\n",
    "        nn.init.constant_(self.fc2.bias, 0)\n",
    "        nn.init.normal_(self.fc3.weight,std=0.02)\n",
    "        nn.init.constant_(self.fc3.bias, 0)\n",
    "        \n",
    "    def forward(self, input_arg):\n",
    "        output = F.elu(self.fc1(input_arg))\n",
    "        output = F.elu(self.fc2(output))\n",
    "        output = self.fc3(output)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T01:48:52.988345254Z",
     "start_time": "2023-09-29T01:48:52.983356493Z"
    }
   },
   "id": "25480b9c7dfb0bfc"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def mutual_information(joint, marginal, mine_net):\n",
    "    t = mine_net(joint)\n",
    "    et = torch.exp(mine_net(marginal))\n",
    "    mi_lb = torch.mean(t) - torch.log(torch.mean(et))\n",
    "    return mi_lb, t, et\n",
    "\n",
    "def learn_mine(batch, mine_net, mine_net_optim,  ma_et, ma_rate=0.01, device_arg=None):\n",
    "    if device_arg is None:\n",
    "        device_arg = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # batch is a tuple of (joint, marginal)\n",
    "    joint, marginal = batch\n",
    "    joint, marginal = joint.to(device_arg), marginal.to(device_arg) \n",
    "    mi_lb, t, et = mutual_information(joint, marginal, mine_net)\n",
    "    ma_et = (1-ma_rate)*ma_et + ma_rate*torch.mean(et)\n",
    "    \n",
    "    # unbiasing use moving average\n",
    "    loss = -(torch.mean(t) - (1/ma_et.mean()).detach()*torch.mean(et))\n",
    "    # use biased estimator\n",
    "    # loss = - mi_lb\n",
    "    \n",
    "    mine_net_optim.zero_grad()\n",
    "    autograd.backward(loss)\n",
    "    mine_net_optim.step()\n",
    "    return mi_lb, ma_et\n",
    "\n",
    "def train(data, mine_net, mine_net_optim, batch_size=100, iter_num=int(5e+3), log_freq=100, device_arg=None):\n",
    "    # data is x or y\n",
    "    result = list()\n",
    "    ma_et = 1.\n",
    "    for i in range(iter_num):\n",
    "        batch = sample_for_iteration(batch_size, data)\n",
    "        mi_lb, ma_et = learn_mine(batch, mine_net, mine_net_optim, ma_et, device_arg=device_arg)\n",
    "        result.append(mi_lb.detach().cpu().numpy())\n",
    "        if (i+1) % log_freq ==0:\n",
    "            print(result[-1])\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T01:48:54.935012869Z",
     "start_time": "2023-09-29T01:48:54.928569755Z"
    }
   },
   "id": "dde84a78323e7636"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "mine_net_sss = Mine(input_size=2 * (degree_of_poly_T - 1) + 3).to(device)\n",
    "mine_net_optim_sss = optim.Adam(mine_net_sss.parameters(), lr=1e-3)\n",
    "result_sss = train(mutual_information_dataset, mine_net_sss, mine_net_optim_sss, log_freq=10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f904bdfc8ad52e3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
